{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241e3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2729f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data as CSV \n",
    "df = pd.read_csv('./politifact_phase1_raw_2018_7_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "48dbbcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of rows missing values is: 0.007727\n"
     ]
    }
   ],
   "source": [
    "#get them number of missing values\n",
    "number_of_missing_values = len(np.where(pd.isnull(df))[0])\n",
    "data_size = len(df)\n",
    "perc = number_of_missing_values/data_size\n",
    "print('The percentage of rows missing values is: %f' % (perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9e6ca0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If Percentage is low enough (< 0.01) drop the values \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c14089c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data by politicfacts also contains a small amount of data without an indication of the truth of the claim but on how an opionion has changed\n",
    "#this data is diregarded here\n",
    "df = df[df.fact_tag_phase1 != 'Full Flop']\n",
    "df = df[df.fact_tag_phase1 != 'Half Flip']\n",
    "df = df[df.fact_tag_phase1 != 'No Flip']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b092d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "355523ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the author\n",
    "df['author'] = df['article_claim_citation_phase1'].str.extract(r'((?<=â€” ).+?(?=\\son))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "849d8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract time correctly\n",
    "df['hour'] = df['article_published_date_phase1'].str.extract(r'((?<=at\\s).+)')\n",
    "df['day'] = df['article_published_date_phase1'].str.extract(r'((?<=\\s)[0-9]+(?=[a-z]+))')\n",
    "df['month'] = df['article_published_date_phase1'].str.extract(r'((?<=,\\s).*?(?=\\s[0-9]+.+,))')\n",
    "df['day_of_the_week'] = df['article_published_date_phase1'].str.extract(r'(.+(?=,.*, ))')\n",
    "df['year'] = df['article_published_date_phase1'].str.extract(r'((?<=,\\s)\\d+(?=\\sat))')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0723da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these columns were processed and will not be needed in the \n",
    "df = df.drop(columns=['article_published_date_phase1', 'article_claim_citation_phase1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "46d77a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This regex is the result of hours of trying, it is not perfect as sometimes www. is included, sometimes not\n",
    "#however this solution finds the same identifier for every link and the platform is always completely contained and is therefore preferred\n",
    "df['platform'] = df['original_url_phase1'].str.extract(r'((?<=\\/\\/)[^\\/]+(?=\\.))')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ffcc1df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following labels exist:\n",
      "['Pants on Fire!' 'False' 'Mostly True' 'Half-True' 'True' 'Mostly False']\n"
     ]
    }
   ],
   "source": [
    "#to represent the hierarchy of the data a key will induced on the labels here already\n",
    "#create a key for the entries\n",
    "idx = range(0,len(df))\n",
    "print('The following labels exist:')\n",
    "print(df['fact_tag_phase1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d2ab8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the previous output gave 6 labels the transformation was correct and a key for every label will be introduced\n",
    "d = {\n",
    "    'Pants on Fire!': 0,\n",
    "    'False': 1,\n",
    "    'Mostly False': 2,\n",
    "    'Half-True' : 3,\n",
    "    'Mostly True' : 4,\n",
    "    'True' : 5\n",
    "}\n",
    "df['label'] = df['fact_tag_phase1'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4736ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#because Hive can not parse text in quotatation marks there needs to be preprocessing\n",
    "#furthermore, there are problems with \",\" values, they are escaped by '~' in this project\n",
    "#therefore this section does replacements to ensure the data is parsed correctly by hive\n",
    "\n",
    "df['article_title_phase1'] = df['article_title_phase1'].str.replace(',','~,')\n",
    "df['article_claim_phase1'] = df['article_claim_phase1'].str.replace(',','~,')\n",
    "df['article_categories_phase1'] = df['article_categories_phase1'].str.replace(',','~,')\n",
    "df['article_researched_by_phase1'] = df['article_researched_by_phase1'].str.replace(',','~,')\n",
    "df['article_edited_by_phase1'] = df['article_edited_by_phase1'].str.replace(',','~,')\n",
    "df['original_url_phase1'] = df['original_url_phase1'].str.replace('~','(clean-tild)')\n",
    "df['original_url_phase1'] = df['original_url_phase1'].str.replace(',','~,')\n",
    "df['author'] = df['author'].str.replace(',','~,')\n",
    "\n",
    "\n",
    "df['original_url_phase1'] = df['original_url_phase1'].str.replace('\\r\\n','')\n",
    "df['article_claim_phase1'] = df['article_claim_phase1'].str.replace('\\r\\n','')\n",
    "df['article_claim_phase1'] = df['article_claim_phase1'].str.replace('-','')\n",
    "\n",
    "df['article_title_phase1'] = df['article_title_phase1'].str.replace('\"','')\n",
    "df['article_claim_phase1'] = df['article_claim_phase1'].str.replace('\"','')\n",
    "df['platform'] = df['platform'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6781e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some changes to make sure that the data will be interpeted correctly by hive\n",
    "df['eval_key'] = idx\n",
    "df['source_key'] = idx\n",
    "\n",
    "#df['measure_claim_length']  = df['article_claim_phase1'].str.len()\n",
    "df.page_is_first_citation_phase1 = df.page_is_first_citation_phase1.apply(str)\n",
    "df['page_is_first_citation_phase1'] = df['page_is_first_citation_phase1'].str.upper() \n",
    "\n",
    "df['content_key'] = idx\n",
    "df['date_key'] = idx\n",
    "\n",
    "#save the file as csv\n",
    "df.to_csv('hive_data.csv', index = False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
